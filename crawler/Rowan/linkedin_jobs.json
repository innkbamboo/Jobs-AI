[
    {
        "title": "Data Centre Chief Engineer, Data Centre Engineering Operations",
        "company": "Amazon Web Services (AWS)",
        "location": "Melbourne, Victoria, Australia",
        "company_id": "2382910",
        "company_url": "https://www.linkedin.com/company/amazon-web-services",
        "employment_type": "Full-time",
        "seniority_level": "",
        "industries": [
            "IT Services and IT Consulting"
        ],
        "job_functions": [
            "Information Technology",
            "Consulting",
            "Engineering"
        ],
        "applies": 33,
        "workplace_type": "N/A",
        "description": "Description\n\nAmazon Web Services (AWS) is looking for a highly motivated Chief Engineer to join our Data Centre Engineering Operations (DCEO) Team. This committed group works to maintain the critical physical infrastructure that supports AWS. Specifically, this team works to ensure that the data centre's Mechanical/Electrical/Plumbing (MEP) operates at 100% availability, while maintaining first-class customer service to the teams and groups within the data centres. The Data Centre Chief Engineer (CE) is responsible for ensuring that all electrical, mechanical, and fire/life safety equipment within the data centre is operating at peak efficiency. This involves planned preventative maintenance of equipment, daily corrective work, and emergency response. The CE serves as an expert technical resource interacting with onsite Engineering Operations Technicians (EOT) and any third party vendors. They are expected to be a singular focal point for all facility operations within a given data centre and to support AWS.\n\nThe CE manages small-to-medium projects from conception to completion. As well as own cluster-wide technical programs that monitor and maintain the effectiveness of DCEO equipment and staff. These projects and programs involve large amounts of independent work as well as collaboration with external support groups including engineering, automation, processing, and finance in both local and global settings. The CE will be tasked with creating and delivering on key milestones, obtaining and tracking quotes for all necessary costs, and documenting project results for future implementation at other facilities. The goals of such projects are for the CE to drive innovation and resiliency while reducing operational costs in the facilities.\n\nThe CE directs, trains and supports EOT\u2019s in their role of providing hands-on electrical and mechanical equipment troubleshooting and operations. Implementation and execution of site/equipment-specific training exercises is also expected. This equipment includes, but is not limited to, stand-by diesel generators, switchgear, UPS\u2019s, PDU\u2019s, DAHU\u2019s, chillers, chemical treatment systems, pumps, motors, VFD\u2019s, and building automation systems.\n\nKey job responsibilities\n\n Cover gaps in a 24 x 7 rotating shift roster. Responsible for the on-site management of contractors, sub-contractors and vendors, ensuring that all work performed, is in accordance with established practices, procedures & local legislation. Establish performance benchmarks, conduct analyses & prepare reports on all aspects of the critical facility infrastructure operations & maintenance. Generate Change Management requests & Incident Management tickets for events that DCEO are responsible to manage. Work with DC managers (IT) and other business leaders to coordinate projects, manage capacity, and optimize plant safety, performance, reliability, sustainability and efficiency. Establish documentation relevant to business & facility operations. Responsible for the installation of the racks and the provision of power/cooling within it's constraints. Review the management of both routine maintenance and emergency services on a variety of critical systems such as: switchgear, generators, UPS systems, power distribution equipment, chillers, cooling towers, computer room air handlers, building monitoring systems, etc. Assist in the design, implementation, commissioning and build out of new facilities. Drive & implement projects to increase current facility capacity, efficiency, sustainability & reliability. Management of the Facility assets and the provision of infrastructure & inventory asset management. Attend and participate in regular Construction & Operational Meetings as required. Familiar with Work Order compliance to ensure all contractual SLA\u2019s are achieved. Interface with Infra Ops management for day to day operational requirements. Assist in recruiting efforts. Assist in the the resolution of any infrastructure engineering or services issue. Delivery of exceptional customer service and satisfaction. Day to day supervision of a team of Engineering Operation technicians.\n\nHold or be able to attain an Australian Government Security Vetting Agency clearance (see https://www.agsva.gov.au/applicants/eligibility-and-suitability)\n\nAbout The Team\n\nAWS Infrastructure Services owns the design, planning, delivery, and operation of all AWS global infrastructure. In other words, we\u2019re the people who keep the cloud running. We support all AWS data centres and all of the servers, storage, networking, power, and cooling equipment that ensure our customers have continual access to the innovation they rely on. We work on the most challenging problems, with thousands of variables impacting the supply chain \u2014 and we\u2019re looking for talented people who want to help. You\u2019ll join a diverse team of software, hardware, and network engineers, supply chain specialists, security experts, operations managers, and other vital roles. You\u2019ll collaborate with people across AWS to help us deliver the highest standards for safety and security while providing seemingly infinite capacity at the lowest possible cost for our customers. And you\u2019ll experience an inclusive culture that welcomes bold ideas and empowers you to own them to completion. We are experiencing rapid growth, therefore your onboarding will be dynamic in nature, where you will gain diverse experience working in new and established AWS data centre's. These future Amazonians will rotate through various AWS locations to complete training as part of their onboarding to prepare for deployment in a data centre region. This training will be completed over a duration of 6-12 months. Once training is completed, individuals will be relocated to the permanent location.\n\nAbout AWS\n\nDiverse Experiences\n\nAWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn\u2019t followed a traditional path, or includes alternative experiences, don\u2019t let it stop you from applying.\n\nWhy AWS?\n\nAmazon Web Services (AWS) is the world\u2019s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating \u2014 that\u2019s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.\n\nInclusive Team Culture\n\nHere at AWS, it\u2019s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.\n\nMentorship & Career Growth\n\nWe\u2019re continuously raising our performance bar as we strive to become Earth\u2019s Best Employer. That\u2019s why you\u2019ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.\n\nWork/Life Balance\n\nWe value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there\u2019s nothing we can\u2019t achieve in the cloud.\n\nBasic Qualifications\n\n Ability to participate and manage a 24 x 7 rotating shift roster with team leadership experience. 4+ years of relevant work experience in maintaining a DC or Critical Space facility, or other critical environment with Technical (Military/Trade School) training Strong verbal and written communication skills.\n\nPreferred Qualifications\n\n Further education in Electrical Engineering, Mechanical Engineering or relevant discipline.\n\nAcknowledgement Of Country\n\nIn the spirit of reconciliation Amazon acknowledges the Traditional Custodians of country throughout Australia and their connections to land, sea and community. We pay our respect to their elders past and present and extend that respect to all Aboriginal and Torres Strait Islander peoples today.\n\nIDE Statement\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer, and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected attributes.\n\n\nCompany - Amazon Corporate Services Pty Ltd\n\nJob ID: A2737498",
        "skills": [
            "Communication",
            "Data Center Infrastructure",
            "Documentation",
            "Focal Point",
            "From Conception to Completion",
            "Incident Management",
            "Operational Requirements",
            "Racks",
            "Reliability",
            "Troubleshooting"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4005287772",
        "reposted": true,
        "posted_time": "2024-12-04 10:49:44",
        "expire_time": "2025-02-16 03:22:42",
        "apply_url": "https://www.amazon.jobs/jobs/2737498/data-centre-chief-engineer-data-centre-engineering-operations?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid"
    },
    {
        "title": "Data Operations Engineer (AWS) ",
        "company": "Robert Half",
        "location": "Greater Sydney Area",
        "company_id": "1681",
        "company_url": "https://www.linkedin.com/company/robert-half-international",
        "employment_type": "Full-time",
        "seniority_level": "Mid-Senior level",
        "industries": [
            "Financial Services"
        ],
        "job_functions": [
            "Information Technology"
        ],
        "applies": 4,
        "workplace_type": "Hybrid",
        "description": "THE COMPANY: \nThis company is a well-known, prestigious, and high-profile Financial Services firm who employ 1200+ staff.\nThey attract employees who adopt an \u2018effort vs reward mindset\u2019 and thrive undertaking meaningful, impactful + visible work, whilst still operating in collaborative environment that encourages ongoing learning, knowledge sharing + proactive innovation.\nHybrid working available.\n\nROLE & RESPONSIBILITIES:\nData Operations Engineer role responsible for ensuring operational performance, support, troubleshooting, and ongoing enhancement of this customer-facing data & analytics platform hosted on-prem and in AWS.\nThis is an operationally focused role involving Incident / Problem / Change Management.\nHybrid working (3 days in office, 2 days WFH).\nDuties include:Implement, maintain, automate, optimize, and operate HA and scalable datasets, pipelines & analytics on AWS and on-prem platforms.Operational support including Incident / Problem / Change Management; Root Cause Analysis; BAU maintenance; and monitoring/alerts etc.Work with Data Engineering & DevOps teams to support data ingestion, processing & analytics workflows.Configure & administer streamlined data access.Platform monitoring & capacity planning \u2013 including performance, capacity, security, data quality, future needs etc.Build & deploy services using Terraform.Apply data governance & security standards to the data platform.Non-functional testing.Project involvement.Involvement in paid on-call support and after-hours roster once every 3 weeks.\n\nREQUIRED BACKGROUND / KNOWLEDGE / EXPERIENCE / PERSONAL QUALITIES \nSuitable for a Data Operations Engineer experienced with AWS data product + proven operational experience supporting, monitoring & improving critical HA platforms.\nIdeal for someone curious, who loves to learn, and has a genuine interest in the evolution of technology.\nThe following is required:Proven Data Operations Engineering background providing operational application/platform support inside in high availability / real time processing environments.AWS data pipeline & analytics experience (e.g. AWS DataZone, Lake Formation, Glue, Athena, MWAA, Redshift etc).IaC experience with Terraform is needed.Well-developed experience with Incident / Problem/ Change Management.Scripting skills \u2013 preferably Python or SQL.Demonstrate strong technical triage & troubleshooting skills and logical problem-solving abilities.Flexible and adaptable personality capable of decisively making decisions.Display curiosity and an eagerness/enthusiasm to learn.Enjoy taking ownership/accountability and be a collaborative team player.\n\nThis is a full time permanent role located in the Sydney CBD (hybrid working) and is offering $130,000 - $143,497 (plus super) + bonus potential. \n*Please note, full permanent Australian working rights (citizenship or PR) are required to be considered for this position and successful applicants will be contacted.",
        "skills": [
            "AWS Glue",
            "Amazon Athena",
            "Amazon Redshift",
            "Application Support",
            "Change Management",
            "Data Operations",
            "Incident Management",
            "Problem Management",
            "Python (Programming Language)",
            "Terraform"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4089411113",
        "reposted": false,
        "posted_time": "2024-12-04 07:01:32",
        "expire_time": "2025-01-03 07:01:31",
        "apply_url": "https://www.linkedin.com/job-apply/4089411113"
    },
    {
        "title": "Data Centre Chief Engineer, Data Centre Engineering Operations",
        "company": "Amazon",
        "location": "Melbourne, Victoria, Australia",
        "company_id": "1586",
        "company_url": "https://www.linkedin.com/company/amazon",
        "employment_type": "Full-time",
        "seniority_level": "",
        "industries": [
            "Software Development"
        ],
        "job_functions": [
            "Information Technology",
            "Consulting",
            "Engineering"
        ],
        "applies": 0,
        "workplace_type": "N/A",
        "description": "Description\n\nAWS Infrastructure Services owns the design, planning, delivery, and operation of all AWS global infrastructure. In other words, we\u2019re the people who keep the cloud running. We support all AWS data centres and all of the servers, storage, networking, power, and cooling equipment that ensure our customers have continual access to the innovation they rely on. We work on the most challenging problems, with thousands of variables impacting the supply chain \u2014 and we\u2019re looking for talented people who want to help. You\u2019ll join a diverse team of software, hardware, and network engineers, supply chain specialists, security experts, operations managers, and other vital roles. You\u2019ll collaborate with people across AWS to help us deliver the highest standards for safety and security while providing seemingly infinite capacity at the lowest possible cost for our customers. And you\u2019ll experience an inclusive culture that welcomes bold ideas and empowers you to own them to completion\n\nAmazon Web Services (AWS) is looking for a highly motivated Chief Engineer to join our Data Centre Engineering Operations (DCEO) Team. This committed group works to maintain the critical physical infrastructure that supports AWS. Specifically, this team works to ensure that the data centre's Mechanical/Electrical/Plumbing (MEP) operates at 100% availability, while maintaining first-class customer service to the teams and groups within the data centres. The Data Centre Chief Engineer (CE) is responsible for ensuring that all electrical, mechanical, and fire/life safety equipment within the data centre is operating at peak efficiency. This involves planned preventative maintenance of equipment, daily corrective work, and emergency response. The CE serves as an expert technical resource interacting with onsite Engineering Operations Technicians (EOT) and any third party vendors. They are expected to be a singular focal point for all facility operations within a given data centre and to support AWS.\n\nThe CE manages small-to-medium projects from conception to completion. As well as own cluster-wide technical programs that monitor and maintain the effectiveness of DCEO equipment and staff. These projects and programs involve large amounts of independent work as well as collaboration with external support groups including engineering, automation, processing, and finance in both local and global settings. The CE will be tasked with creating and delivering on key milestones, obtaining and tracking quotes for all necessary costs, and documenting project results for future implementation at other facilities. The goals of such projects are for the CE to drive innovation and resiliency while reducing operational costs in the facilities.\n\nThe CE directs, trains and supports EOT\u2019s in their role of providing hands-on electrical and mechanical equipment troubleshooting and operations. Implementation and execution of site/equipment-specific training exercises is also expected. This equipment includes, but is not limited to, stand-by diesel generators, switchgear, UPS\u2019s, PDU\u2019s, DAHU\u2019s, chillers, chemical treatment systems, pumps, motors, VFD\u2019s, and building automation systems.\n\nKey job responsibilities\n\n Cover gaps in a 24 x 7 rotating shift roster. Responsible for the on-site management of contractors, sub-contractors and vendors, ensuring that all work performed, is in accordance with established practices, procedures & local legislation. Establish performance benchmarks, conduct analyses & prepare reports on all aspects of the critical facility infrastructure operations & maintenance. Generate Change Management requests & Incident Management tickets for events that DCEO are responsible to manage. Work with DC managers (IT) and other business leaders to coordinate projects, manage capacity, and optimize plant safety, performance, reliability, sustainability and efficiency. Establish documentation relevant to business & facility operations. Responsible for the installation of the racks and the provision of power/cooling within it's constraints. Review the management of both routine maintenance and emergency services on a variety of critical systems such as: switchgear, generators, UPS systems, power distribution equipment, chillers, cooling towers, computer room air handlers, building monitoring systems, etc. Assist in the design, implementation, commissioning and build out of new facilities. Drive & implement projects to increase current facility capacity, efficiency, sustainability & reliability. Management of the Facility assets and the provision of infrastructure & inventory asset management. Attend and participate in regular Construction & Operational Meetings as required. Familiar with Work Order compliance to ensure all contractual SLA\u2019s are achieved. Interface with Infra Ops management for day to day operational requirements. Assist in recruiting efforts. Assist in the the resolution of any infrastructure engineering or services issue. Delivery of exceptional customer service and satisfaction. Day to day supervision of a team of Engineering Operation technicians.\n\nHold or be able to attain an Australian Government Security Vetting Agency clearance (see https://www.agsva.gov.au/applicants/eligibility-and-suitability)\n\nAbout The Team\n\nWe are experiencing rapid growth, therefore your onboarding will be dynamic in nature, where you will gain diverse experience working in new and established AWS data centre's. These future Amazonians will rotate through various AWS locations to complete training as part of their onboarding to prepare for deployment in a data centre region. This training will be completed over a duration of 6-12 months. Once training is completed, individuals will be relocated to the permanent location.\n\nAbout AWS\n\nDiverse Experiences\n\nAWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn\u2019t followed a traditional path, or includes alternative experiences, don\u2019t let it stop you from applying.\n\nWhy AWS?\n\nAmazon Web Services (AWS) is the world\u2019s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating \u2014 that\u2019s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.\n\nInclusive Team Culture\n\nHere at AWS, it\u2019s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.\n\nMentorship & Career Growth\n\nWe\u2019re continuously raising our performance bar as we strive to become Earth\u2019s Best Employer. That\u2019s why you\u2019ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.\n\nWork/Life Balance\n\nWe value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there\u2019s nothing we can\u2019t achieve in the cloud.\n\nBasic Qualifications\n\n Ability to participate and manage a 24 x 7 rotating shift roster with team leadership experience. 4+ years of relevant work experience in maintaining a DC or Critical Space facility, or other critical environment with Technical (Military/Trade School) training Strong verbal and written communication skills.\n\nPreferred Qualifications\n\n Further education in Electrical Engineering, Mechanical Engineering or relevant discipline.\n\nAcknowledgement Of Country\n\nIn the spirit of reconciliation Amazon acknowledges the Traditional Custodians of country throughout Australia and their connections to land, sea and community. We pay our respect to their elders past and present and extend that respect to all Aboriginal and Torres Strait Islander peoples today.\n\nIDE Statement\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer, and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected attributes.\n\n\nCompany - Amazon Corporate Services Pty Ltd\n\nJob ID: A2845088",
        "skills": [
            "Benchmarking",
            "Communication",
            "Customer Service",
            "Data Center Infrastructure",
            "Operational Requirements",
            "Project Management",
            "Reliability",
            "Training",
            "Troubleshooting",
            "Written Communication"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4090613878",
        "reposted": false,
        "posted_time": "2024-12-04 09:12:02",
        "expire_time": "2025-01-03 09:12:02",
        "apply_url": "https://www.amazon.jobs/jobs/2845088/data-centre-chief-engineer-data-centre-engineering-operations?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid"
    },
    {
        "title": "AI Backend Engineer-Mandarin Speaker",
        "company": "MyShell.ai",
        "location": "APAC",
        "company_id": "100595389",
        "company_url": "https://www.linkedin.com/company/ai-myshell",
        "employment_type": "Full-time",
        "seniority_level": "Mid-Senior level",
        "industries": [
            "Software Development"
        ],
        "job_functions": [
            "Information Technology",
            "Engineering"
        ],
        "applies": 1,
        "workplace_type": "Remote",
        "description": "About MyShellMyShell is revolutionizing the AI landscape by building an open ecosystem for AI-native apps. Our powerful platform and intuitive toolkit empower anyone to create, access, and benefit from AI-powered applications. Launched in April 2023, MyShell has quickly gained global traction, attracting a diverse community of creators and users.Our team of talented individuals from top institutions like MIT, Princeton, and Oxford is committed to fostering innovation in a supportive and transparent work environment. With funding from leading VCs, MyShell is poised to reshape the future of AI, making it accessible and integral to everyone's daily life. Join us on this thrilling journey as we redefine what's possible with AI.\nAbout the RoleWe are seeking an exceptional Senior Backend Engineer to join our team as a Tech Lead. This is a fully remote position open to candidates in either the United States or China.In this role, you will be a cornerstone of our engineering team, driving the development of our backend systems. You will be responsible for creating robust, scalable services that power our AI platform, collaborating with frontend developers, and leading the development of new features and infrastructure improvements.\nKey Responsibilities\u2022 Develop and maintain scalable and robust backend services and APIs.\u2022 Collaborate with frontend developers to integrate user-facing elements with server-side logic. \u2022 Implement high-performance database queries and tune databases for performance.\u2022 Ensure the best possible reliability, quality, and responsiveness of applications.\u2022 Lead the development of new features and infrastructure improvements.\u2022 Write clean, maintainable, and well-documented code in accordance with current best practices.\u2022 Mentor junior engineers and promote a culture of technical excellence.\nQualifications\u2022 Bachelor's or Master's degree in Computer Science or related field, or equivalent experience.\u2022 1-3 years of experience in backend development with a strong knowledge of backend languages, such as Golang/Python.\u2022 Proficiency in designing and managing database systems such as MySQL and MongoDB.\u2022 Experience with cloud services (AWS, Azure, GCP) and understanding of scalable infrastructure.\u2022 Familiarity with distributed back-end service development processes and specifications, along with commonly used development frameworks.\u2022 Strong understanding of security practices and networking protocols.\u2022 Fluency in Chinese (Mandarin).\nPlus Points\u2022 Exceptional problem-solving abilities and strong communication skills.\u2022 Experience with AI or machine learning technologies and their integration into backend systems.\u2022 Contributions to open-source projects or a strong presence in the developer community.\u2022 Prior experience in a fast-paced startup environment.\nWhat We Offer\u2022 Competitive salary and equity package, commensurate with experience and location.\u2022 Flexible working hours and a fully remote work environment, with the ability to collaborate effectively across time zones.\u2022 A dynamic and collaborative work environment that fosters innovation, growth, and professional development.\u2022 The opportunity to work on cutting-edge technologies and help shape the future of AI, transforming industries and making a global impact.",
        "skills": [
            "Amazon Web Services (AWS)",
            "Artificial Intelligence (AI)",
            "Cloud Services",
            "Computer Science",
            "Go (Programming Language)",
            "Google Cloud Platform (GCP)",
            "Machine Learning",
            "MongoDB",
            "MySQL",
            "Remote Work"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4089967982",
        "reposted": false,
        "posted_time": "2024-12-04 11:55:40",
        "expire_time": "2025-02-02 11:50:43",
        "apply_url": "https://boards.greenhouse.io/myshell/jobs/4005792008?source=LinkedIn"
    },
    {
        "title": "Data Engineer",
        "company": "Roy Morgan",
        "location": "Melbourne, Victoria, Australia",
        "company_id": "19342",
        "company_url": "https://www.linkedin.com/company/roymorganaus",
        "employment_type": "Full-time",
        "seniority_level": "Mid-Senior level",
        "industries": [
            "Data Infrastructure and Analytics",
            "Software Development",
            "Technology, Information and Media"
        ],
        "job_functions": [
            "Engineering",
            "Information Technology",
            "Research"
        ],
        "applies": 32,
        "workplace_type": "On-site",
        "description": "About Roy Morgan \n Roy Morgan is Australia's most reputable and longest established market research company, with an unparalleled reputation for reliable, accurate, meaningful, revealing market research. At the forefront of data and research innovation since 1941, today Roy Morgan continues to provide accurate and independent information insights to leading Australian and international companies and governments, as well as partnering with these same companies on bespoke data applications and technology development.\n \n \n About The Role \n The Technology department is responsible for positioning Roy Morgan as an efficient and innovative Research Company that employs best in breed technologies and methodologies to generate powerful insights for its customers. \n \n With this newly created role, we are seeking a Data Engineer to join the Information Technology team with a laser focus on R&D, mapping and implementation of a wider Data Lake/Warehouse strategy, with a strong emphasis on AWS technologies and a driving force with our transformation journey. This is a unique opportunity to assist in developing new ways of working with our world-renowned data sets. \n \n Reporting to the Head of Information Technology, the Data Engineer will initially focus on helping us with R&D on transforming older data stores into high performing data engines, data engine selection, specifically for wide columnar storage and processing engines, fast query performance etc and continuous improvement on data sets, their storage and transformation. The initial work will involve data modelling and testing in several technology stacks/engines, with a focus on building real time analysis queries to upgrade our client facing API backends. Moving beyond, you will be an integral part of helping the company modernise our Data Lake/Warehouse and all associated data management and pipelines, including being a part of the team that develops, implements and maintains the company's Data Lake/Warehouse strategy.\n \n The Data Engineer will work closely with Data Scientists in building analytics models, automating internal processes and finding new and better ways to warehouse and process data to help improve our products and business decisions. The successful candidate will collaborate with product managers, fellow engineers, and other stakeholders to deliver top-notch data-driven solutions for our customers.\n \n \n About You\n Ideally, your skills and experience should include:Bachelor's degree in Information Technology or Data SciencePrevious experience in Data Engineering or similar role, preferably within \"big data\" and/or the Market Research industryStrong background in data pipeline design, ETL processes, and data modellingStrong practical programming skills in R/Python, SQLDeep understanding of Devops principles, with relation to Data EngineeringProficiency in AWS Services including Redshift, Keyspaces, EMR, Lake Formation, Glue jobs, S3, Lambdas, Fargate etcStrong analytical, problem-solving, conceptual and research skillsPractical experience in applying AI and machine learning for real-world solutionsKnowledge of data management and visualization techniquesProven ability to work simultaneously across a variety of different projects and initiatives, while working autonomously, as part of a team and collaborativelyWell-developed communication skills with the ability to convey complex concepts to technical and non-technical stakeholdersAchievement oriented with proven experience of being a part of a cross skilled, motivated and cohesive team Our Offer to You \n We believe in investing in our people and when you join us, you can expect:Vibrant work cultureCompetitive salary packageCompany social events, including Friday night activitiesCompany EAP serviceBenefits including entertainment events, annual flu vaccine, discounted MYKI passes, and corporate discount for health insurance\n \n Roy Morgan values diversity and is committed to building an inclusive workplace culture that reflects our community. We encourage diversity and recognise the enrichment diversity brings to our business and people - whether its diversity of skill, experience and/or background. We welcome applications from diverse backgrounds and community groups including Aboriginal and Torres Strait Islander peoples.\n \n This is a fantastic opportunity to join the Technology team at a time of transformational change and if it sounds like your next opportunity, then apply now!\n",
        "skills": [
            "Amazon Redshift",
            "Analytical Skills",
            "Communication",
            "Data Analytics",
            "Data Engineering",
            "Data Modeling",
            "Data Pipelines",
            "Data Science",
            "Extract, Transform, Load (ETL)",
            "Problem Solving"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4088582876",
        "reposted": false,
        "posted_time": "2024-12-03 23:26:18",
        "expire_time": "2025-01-02 23:25:39",
        "apply_url": "https://www.aplitrak.com/?adid=ZWR3YXJkLmFuZy40NjM1MS4xNTUwQHJveW1vcmdhbmF1LmFwbGl0cmFrLmNvbQ"
    },
    {
        "title": "Senior Data Engineer",
        "company": "Jemena",
        "location": "Melbourne, Victoria, Australia",
        "company_id": "307113",
        "company_url": "https://www.linkedin.com/company/jemena",
        "employment_type": "Full-time",
        "seniority_level": "Mid-Senior level",
        "industries": [
            "Utilities"
        ],
        "job_functions": [
            "Information Technology"
        ],
        "applies": 0,
        "workplace_type": "On-site",
        "description": "Gender neutral paid parental leave (no min service + continued super.)Permanent role & hybrid Flexible working, empowered to work agile!Competitive salary plus annual bonus and other company benefits\n\nWho We Are\n\nJemena is an Australian energy company who own and operate more than $12.4 Billion worth of gas and electricity transportation assets across Australia supplying millions of households and businesses with these essential services every day.\n\nWe pride ourselves on our innovative approach, technical expertise, and dedication to safety, quality, and sustainability. Our Group\u2019s over 3000 team members, consistently strive to make a difference in the communities we serve.\n\nOverview Of Our Role\n\nAs Senior Data Engineer you will be empowered to build, optimise, and maintain Jemena\u2019s data pipelines and ETL processes to support data-driven decision-making across business units. Your role will focus on developing robust data solutions within Databricks, covering Bronze, Silver, and Gold medallion layers to ensure data integrity, accessibility, and performance.\n\nPlay a key role in orchestrating data workflows, managing dependencies, and leveraging tools like Apache Airflow, DBT core, and Spark to develop efficient data models and processing pipelines. Bring your expertise and passion in data engineering best practices, including data extraction, transformation, and integration from various internal and external sources. Collaborate with line-of-business teams to understand data requirements and ensure the delivery of high-quality, reliable data products.\n\nBy ensuring the continuous optimisation and scalability of Jemena\u2019s data engineering infrastructure, you will empower Jemena to derive actionable insights and drive business outcomes.\n\nA Little About You\n\nDemonstrated experience in designing and optimizing (AWS)cloud-based data pipelines and ETL processes with a focus on data quality and performance.Proficiency in using Databricks to manage data flows across Bronze, Silver, and Gold layers, supporting efficient data architectures.Expertise in data orchestration tools such as Apache Airflow, DBT, or Databricks Workflows to streamline processes and manage dependencies.Strong skills in Python and SQL for creating scalable data models and transformations, with practical knowledge of integrating data from diverse sources, including APIs and real-time streams.Experience collaborating in agile environments with cross-functional teams to deliver impactful data solutions.Familiarity with Spark, PySpark, Delta Lake, and CI/CD tools such as GitLab to enhance large-scale data processing and infrastructure provisioning. \n\nQualifications / Certifications & Skills\n\nDemonstrated expertise in data engineering principles, focusing on modern data lakehouse architectures in cloud environments.Skilled in using Databricks to design and manage data layers (Bronze, Silver, Gold) for seamless data processing and analytics.Proficient in Git version control for collaborative development and CI/CD pipelines (e.g., GitLab CI/CD) to automate the deployment and testing of data engineering workflows.Proficient in Python and SQL, developing scalable, reusable data transformations and optimizing workflows using tools like Apache Airflow and DBT.Experienced with big data frameworks such as Spark and PySpark to handle complex datasets and enhance ETL performance.Adept at ensuring data security and governance, adhering to best practices and compliance standards.Knowledgeable in integration tools for extracting data from APIs and diverse sources, enabling efficient ingestion and modeling.\n\nWhy you should come and work for us\u202f\n\nOur people are our energy source and we offer meaningful benefits and rewards that work for you. We offer the opportunity for long term career growth as part of our talent development and succession planning process. Join our team and make a meaningful impact toward Australia\u2019s \u201cNet Zero\u201d targets through the delivery of critical infrastructure projects and be a part of our journey to shape the future of the energy and utilities industry.\n\nJemena is among the first companies in Australia to be accredited as a Family Inclusive Workplaceflexible work arrangements, empowered to work your way & agile + additional leave benefits!primary & secondary parental leave & well-being and family support benefitsnumerous career development pathways + yearly financial support to upskillannual bonuses + generous $$$ employee referral programempowering you within a fun, diverse and inclusive culture group benefits galore for all employees!genuine focus on work / life balance \n\nWe are committed to developing a diverse and inclusive workforce that reflects the communities we are part of. We welcome applications from people of all ages, backgrounds, abilities, and identities. At Jemena, you belong.\n\nRecruitment Process\u202f\n\nDuring our recruitment process, you will be required to undergo pre-employment checks including pre-employment medical, reference checks and a national police check. Notice to Third Parties:\u202fJemena does not accept unsolicited resumes (or liability associated with fees or costs) from recruitment agencies, search firms or third parties. Interested candidates are welcome to submit their application independently.\u202f\n\nVideo",
        "skills": [
            "Azure Databricks",
            "Bronze",
            "Data Analytics",
            "Data Engineering",
            "Data Management",
            "Data Models",
            "Data Pipelines",
            "Data Quality",
            "Extract, Transform, Load (ETL)",
            "Silver"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4089497290",
        "reposted": false,
        "posted_time": "2024-12-04 11:52:55",
        "expire_time": "2025-01-03 11:52:55",
        "apply_url": "https://www.careers.jemena.com.au/job-details/senior-data-engineer-in-jobs-1084617"
    },
    {
        "title": "Data Platform Engineer (remote)",
        "company": "iterate",
        "location": "Melbourne, Victoria, Australia",
        "company_id": "19191002",
        "company_url": "https://www.linkedin.com/company/iterate-rec",
        "employment_type": "Full-time",
        "seniority_level": "Mid-Senior level",
        "industries": [
            "IT Services and IT Consulting"
        ],
        "job_functions": [
            "Engineering"
        ],
        "applies": 28,
        "workplace_type": "On-site",
        "description": "We are excited to be partnered with an Australian success story, a leading SaaS company with customers around the globe. Their unique product is driving progress towards a cleaner, greener future.\nAfter success internationally, they are looking for an Engineer to join the team and lead the development of key product components focused on data flows, processing and visualisation.\nYou'll be joining a high-performing, close-knit team of smart & creative Engineers who are based around Australia. They are a remote-first business but offer flexible working options for those who prefer working from an office.\nResponsibilities will include:Leveraging AWS expertise to build scalable, reliable, and highly available systemsDeveloping and optimising data pipelines for seamless transformation and integrationDesigning APIs and event-driven architecture for system interoperabilityEnsuring software scalability and performance for handling large data volumes\nSkills we are looking for:Software engineering background preferred, with experience in API design, CI/CD and data structuresSolid experience designing Python-based data integrations, especially for large-scale time-series dataProficiency in data engineering tools and libraries e.g. Polars, Pandas, NumpyExpertise in ETL pipelines and handling structured/unstructured dataExperience with SQL/NoSQL databases and data warehousing toolsKnowledge of AWS, IaC and serverless event-driven architectures",
        "skills": [
            "Continuous Integration and Continuous Delivery (CI/CD)",
            "Data Warehousing",
            "Databases",
            "Kubernetes",
            "NoSQL",
            "NumPy",
            "Optimising",
            "Pandas (Software)",
            "Python (Programming Language)",
            "SQL"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4088903295",
        "reposted": false,
        "posted_time": "2024-12-04 01:02:16",
        "expire_time": "2025-01-03 01:02:16",
        "apply_url": "https://www.linkedin.com/job-apply/4088903295"
    },
    {
        "title": "Senior Platform Engineer \u2013 Data / AWS Glue",
        "company": "Commonwealth Bank",
        "location": "Melbourne, Victoria, Australia",
        "company_id": "2848",
        "company_url": "https://www.linkedin.com/company/commonwealthbank",
        "employment_type": "Full-time",
        "seniority_level": "Mid-Senior level",
        "industries": [
            "Financial Services"
        ],
        "job_functions": [
            "Engineering",
            "Information Technology"
        ],
        "applies": 2,
        "workplace_type": "Hybrid",
        "description": "You are highly experienced in building customer focussed solutions.We are a team of big thinkers, who love to push boundaries and create new solution.Together we will build tomorrow\u2019s bank today, using world-leading technology and innovation.\n\nDo work that matters:\n\nWe're building tomorrow\u2019s bank today. This means we need creative and diverse engineers to help us redefine what customers expect from a bank. Envisioning new technologies that are still waiting to be invented and reimagining products that support our customers and help build Australia\u2019s future economy.\n\nThe role of Platform Engineers is to design, build, run and evolve tools, infrastructure, templates and capabilities to deliver business value, and write code to drive automation in running our infrastructure and environments.\n\nSee yourself in our team.\n\nCommBank.Data is the emerging Cloud data platform solution consisting of AWS native services and capabilities that ingests data from multiple source systems and executes business use cases for AI, advanced analytics (machine learning) at scale, across the comprehensive dataset and facilitates data discovery by advanced analytics users.\n\nThis role will see you become part of f the wider Data Engineering and Data Platform Chapter. The crew is accountable and responsible for the platform\u2019s availability, performance, security and lifecycle management.\n\nCollaboratively we work to design, build and run \u2018platforms\u2019 to deliver customer value at greater quality, velocity, and safety.\n\nKey Responsibilities:\n\nExpertise in cloud infrastructure design and operations.Develop platform architecture that aligns with Business needs and support system resources in AWS environment across the Group, focusing on high quality, security, scalability, performance, and cost efficiency.Comprehensive understanding of driving automation through understanding processes and implementing improvements.Evaluate new technologies to enhance platform capabilities and reduce operational complexity.Collaborate with Site Reliability Engineers (SRE) to develop and maintain Service Level Objectives (SLOs ) and Service Level Indicators (SLIs).Support customer requests related to platform technical implementation and capabilities.Respond to incidents/problems and perform root cause analysis.Proactively identify and develop solutions to mitigate platform risks against system failure, data loss, inappropriate disclosure or use of data, malicious attacks etc.Manage ongoing environment expansion and life cycle, e.g. system upgrades, security patching.Develop and maintain runbooks, document system configuration and standard operating procedures.\n\nWe\u2019re interested in hearing from people who:\n\nAre experienced Platform Engineers who are familiar with the full cycle model and involved in design, build, challenge and run.Have a background in data engineering specifically working across Teradata and Omnia (Hadoop, Hive) essential.Have a passion for designing, developing, deploying, and running high-quality software and platforms.Contribute to a culture where quality, inclusiveness and excellence are championed.Have a natural drive to educate, communicate and positively influence various stakeholder groups including high level executives.\n\nTech Skill:\n\nWe use a broad range of tools, languages, and frameworks. We don\u2019t expect you to know them all but experience or exposure with some of these (or equivalents) will set you up for success in this team;\n\nHave experience in core AWS services like EC2, VPC, S3, Identity and Access Management (IAM), Lambda and with AWS Managed services - Amazon RDS, Dynamo DB and Redshift essential.Proficient in Python scripting, Bash, or PowerShell to automate tasks, manage configurations and troubleshooting essential.Deep understanding and Hands on experience on AWS CloudWatch, Prometheus, Grafana to ensure proactive issue detection and resolution essential.AWS glue and Lake Formation essential.Teradata, Hadoop and Hive essential.Experience delivering scalable solutions on infrastructure as a code (IaC) using Terraform/AWS Cloud Formation.Good understanding of DevOps and CI/CD tools like GitHub, Jenkins TeamCity CI/CD pipeline, AWS CodePipeline and AWS CodeBuild to automate deployments\n\nIf you're already part of the Commonwealth Bank Group (including Bankwest, x15ventures), you'll need to apply through Sidekick to submit a valid application. We\u2019re keen to support you with the next step in your career.\n\nWe're aware of some accessibility issues on this site, particularly for screen reader users. We want to make finding your dream job as easy as possible, so if you require additional support please contact HR Direct on 1800 989 696.\n\nAdvertising End Date: 17/12/2024",
        "skills": [
            "AWS Glue",
            "Amazon CloudWatch",
            "Automation",
            "Bash",
            "Communication",
            "Grafana",
            "Hive",
            "Root Cause",
            "Root Cause Analysis",
            "Scripting"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4088948153",
        "reposted": false,
        "posted_time": "2024-12-04 02:20:25",
        "expire_time": "2025-01-03 02:20:25",
        "apply_url": "https://cba.wd3.myworkdayjobs.com/CommBank_Careers/job/Sydney-CBD-Area/Senior-Platform-Engineer---Data---AWS-Glue_REQ220466?source=LinkedIn"
    },
    {
        "title": "  AWS Data Engineer",
        "company": "Synechron",
        "location": "Sydney, New South Wales, Australia",
        "company_id": "15506",
        "company_url": "https://www.linkedin.com/company/synechron",
        "employment_type": "Full-time",
        "seniority_level": "",
        "industries": [
            "Information Services"
        ],
        "job_functions": [
            "Information Technology"
        ],
        "applies": 22,
        "workplace_type": "Hybrid",
        "description": "We are seeking an AWS Data Engineer with a strong foundation in AWS services and data ingestion using APIs. This individual will be instrumental in architecting and building scalable data solutions, leveraging AWS technologies such as S3, Redshift, Glue, and EC2 to support our data infrastructure needs.\nKey Responsibilities:Develop and maintain scalable and reliable data pipelines to ingest data from various APIs into the AWS ecosystem.Manage data storage solutions using S3 buckets, ensuring best practices in data organization and security.Utilize AWS Redshift for data warehousing tasks, optimizing data retrieval and query performance.Configure and use AWS Glue for ETL processes, ensuring data is clean, well-structured, and ready for analysis.Utilize EC2 instances for custom applications and services that require compute capacity.Implement data lake and warehousing strategies to support analytics and business intelligence initiatives.Collaborate with cross-functional teams to understand data needs and deliver solutions that align with business goals.Ensure compliance with data governance and security policies.\nQualifications:Solid experience in AWS services, especially S3, Redshift, Glue, and EC2.Proficiency in data ingestion and integration, particularly with APIs.Strong understanding of data warehousing, ETL processes, and cloud data storage.Experience with scripting languages such as Python for automation and data manipulation.Familiarity with infrastructure as code tools for managing AWS resources.Excellent problem-solving skills and ability to work in a dynamic environment.Strong communication skills for effective collaboration and documentation.",
        "skills": [
            "Amazon Redshift",
            "Communication",
            "Data Analytics",
            "Data Engineering",
            "Data Ingestion",
            "Data Lakes",
            "Data Manipulation",
            "Data Warehousing",
            "Extract, Transform, Load (ETL)",
            "Problem Solving"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4089009799",
        "reposted": false,
        "posted_time": "2024-12-04 01:28:40",
        "expire_time": "2025-01-03 01:28:39",
        "apply_url": "N/A"
    },
    {
        "title": "Senior Analytics Engineer",
        "company": "Linktree",
        "location": "Greater Melbourne Area",
        "company_id": "19006475",
        "company_url": "https://www.linkedin.com/company/linktree",
        "employment_type": "Full-time",
        "seniority_level": "Mid-Senior level",
        "industries": [
            "Software Development"
        ],
        "job_functions": [
            "Information Technology"
        ],
        "applies": 34,
        "workplace_type": "Remote",
        "description": "The Role\n\nAs a Senior Analytics Engineer on the Data Platform team, you will play a critical role in building the architecture and tools that power our data analytics and reporting functions. Your expertise in data engineering and analytics will create robust data models, develop advanced analytics solutions, and deliver insights that drive business strategy. Your role will be crucial in influencing the direction of our data platform and ensuring its alignment with the company\u2019s strategic goals.\n\nWhat You'll Own\n\nCore Data Models: Design, develop, and maintain essential data models that will be leveraged across various business functions. Your work will ensure consistency and accuracy in the way data is represented and utilised throughout the company.Standards and Best Practices: Define and implement data engineering standards and best practices. Provide guidance and support to other teams to ensure adherence to these standards, promoting high-quality data processes and governance.Cross-Functional Collaboration: Partner with data scientists, analysts, and engineering teams to understand their requirements and deliver data solutions that align with their needs. Facilitate effective communication and knowledge sharing across teams.Strategic Influence: Play a key role in shaping the future direction of the data platform. Provide strategic insights and recommendations to enhance the platform\u2019s capabilities and its impact on business decision-making.\n\nWho We\u2019re Looking For\n\nExperience: 2+ years of experience in analytics engineering, data engineering or a related role.Technical Skills: Proficiency in SQL and experience with data warehousing solutions (e.g., Snowflake). Knowledge of data engineering tools and frameworks (e.g., Apache Airflow, dbt) and programming languages (e.g., Python).Analytics Tools: Experience with business intelligence tools (e.g., Looker) and data visualisation best practices.Communication: Excellent verbal and written communication skills, with the ability to convey technical concepts to non-technical stakeholders.Experience operating at scale: You have worked on data systems that power a product that serves hundreds of millions of active users.\n\nP.S. If you don\u2019t tick every box in this ad, please don\u2019t rule yourself out. We take pride in inclusion and hiring incredible human beings with great potential over ticking boxes \u2013 so if this role resonates with you, hit that apply button!\n\nWhere And How We Work\n\nWe are a global and diverse group offering a truly flexible and family friendly work environment. Kids, pets, and the occasional delivery person are all actively encouraged to appear on our Zoom screens. All of us at Linktree work either fully remote or a flex hybrid approach.\n\nWe offer autonomy and flexibility in how you structure your days and weeks. There will be the need for some collaboration outside of your usual 9-5 being a global company, but we aim to work asynchronously where possible.\n\nHow We\u2019ll Help You Thrive\n\nOur approach to benefits considers the whole person and the unique contributions they bring to Linktree. We want the experience at Linktree to be one that enables people to truly thrive so we can Go Further Together. Some ways we support you:\n\nAn annual wellbeing allowance to use on things like (but not limited to) fitness memberships, development courses, childcare, travel, charitable donations, pet insurance, home office set up - the choice is yours!100% coverage (and 80% for your dependents) of your monthly premiums for medical, dental, vision, disability and life insurance for US-based employees.Employer contribution towards your retirement.Generous time off for vacation, holidays, parental leave, volunteer time and other categories.Employee Stock Option Program - we want each and every employee to share in the company\u2019s success as we go further together.\n\nTo learn more about our benefits, including our parental leave program, volunteering leave, DE&I initiatives, and more, click here!\n\nOur Story\n\nWe're on a mission to empower anyone to curate, grow and monetize their digital universe. We created the \"link in bio\" category and are trusted by some of the world's biggest brands and celebrities including TikTok, The UN Environmental Program, The White House, F1, Manchester United, Olivia Rodrigo and Selena Gomez. With over 50M+ users and 40,000 new accounts created everyday, Linktree is the fastest growing leader in our category. Linktree has partnered with some of today\u2019s biggest names like Amazon, TikTok, Snap, YouTube, GoFundMe, Spotify, Google, Stripe, Reddit and more to help unify users\u2019 digital spaces\u2014 and we\u2019re just getting started. Join us in empowering everyone from businesses to creatives in building their online presence.\n\nAt Linktree, we celebrate and support everyone\u2019s perspective and background, and we\u2019re proud to be an equal opportunity workplace. We aim to foster a diverse and inclusive environment where all team members have a sense of belonging, because we believe in going further together. Linktree welcomes all people regardless of sex, gender identity, race, ethnicity, disability, pregnancy, age, or other lived experience. If you require accommodations to fully participate in our opportunities, please don't hesitate to reach us at talent@linktr.ee \u2013 your needs are important to us.",
        "skills": [
            "Analytical Skills",
            "Analytics",
            "Communication",
            "Core Data",
            "Data Analytics",
            "Data Engineering",
            "Data Models",
            "Knowledge Sharing",
            "Strategic Influence",
            "Written Communication"
        ],
        "job_url": "https://www.linkedin.com/jobs/view/4088707524",
        "reposted": false,
        "posted_time": "2024-12-03 12:52:54",
        "expire_time": "2025-01-02 12:52:54",
        "apply_url": "https://jobs.gem.com/linktree/8c7b8524-cc61-4e9f-b383-bc0d4b77557d?src=LinkedIn+Paid"
    }
]